import os
import io
import re
from pathlib import Path
from datetime import datetime
from itertools import chain

import pandas as pd
from flask import (
    Flask, render_template, request, send_file, url_for, redirect, jsonify, abort
)
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# -----------------------------------------------------------------------------
# App & Config
# -----------------------------------------------------------------------------
app = Flask(__name__)

# Where we save exports that the STATIC site (or this Flask app) can serve
STATIC_EXPORTS = Path("static/exports")
STATIC_EXPORTS.mkdir(parents=True, exist_ok=True)

# Optional environment variables (used for hints in the UI only)
STATIC_SITE_BASE = os.getenv("STATIC_SITE_BASE", "").strip()  # e.g. https://cwloop-static.onrender.com
STATIC_DATED_SUBFOLDERS = os.getenv("STATIC_DATED_SUBFOLDERS", "true").lower() == "true"

# -----------------------------------------------------------------------------
# Utilities
# -----------------------------------------------------------------------------
TS_COL_CANDIDATES = [
    " Time Stamp", "Time Stamp", "Timestamp", "DateTime", "Date", "Time", "Date/Time"
]

def find_timestamp_column(df: pd.DataFrame) -> str | None:
    """Find the best timestamp column in a dataframe by common names."""
    for c in TS_COL_CANDIDATES:
        if c in df.columns:
            return c
    # otherwise, if the first column looks like datetime-like, accept it
    first = df.columns[0]
    try:
        pd.to_datetime(df[first])
        return first
    except Exception:
        return None

def strip_device_prefix(col: str) -> str:
    """
    Remove device prefix (anything to the left of the first '.').
    Example: 'Plant Pumps.Active CW Flow Setpoint' -> 'Active CW Flow Setpoint'
    """
    if "." in col:
        return col.split(".", 1)[1].strip()
    return col.strip()

def read_csv_storage(file_storage) -> pd.DataFrame:
    """Read uploaded CSV (Werkzeug FileStorage) into DataFrame."""
    raw = file_storage.read()
    df = pd.read_csv(io.BytesIO(raw), encoding_errors="ignore")
    return df

def normalize_datetime_index(df: pd.DataFrame, ts_col: str) -> pd.DataFrame:
    """Ensure datetime index from ts_col and sort; drop duplicates keeping first."""
    df = df.copy()
    df[ts_col] = pd.to_datetime(df[ts_col], errors="coerce")
    df = df.dropna(subset=[ts_col])
    df = df.drop_duplicates(subset=[ts_col], keep="first").sort_values(ts_col)
    df = df.set_index(ts_col)
    return df

def write_directory_index(dir_path: Path, base_href: str = "") -> None:
    """
    Create a simple index.html for a directory to make it browsable.
    `base_href` is the visible URL prefix (e.g. '/static/exports').
    """
    entries = []
    for p in sorted(dir_path.iterdir()):
        name = p.name + ("/" if p.is_dir() else "")
        href = f"{base_href}/{p.name}" if base_href else p.name
        size = "-" if p.is_dir() else f"{p.stat().st_size:,}"
        mtime = datetime.fromtimestamp(p.stat().st_mtime).strftime("%Y-%m-%d %H:%M")
        entries.append((name, href, size, mtime))

    html = [
        "<!DOCTYPE html><html><head><meta charset='utf-8'>",
        "<meta name='viewport' content='width=device-width, initial-scale=1'>",
        "<title>Index of {}</title>".format(base_href or dir_path.name),
        "<style>body{font-family:system-ui,Segoe UI,Arial,sans-serif;padding:20px} "
        "table{border-collapse:collapse;width:100%} th,td{border:1px solid #ddd;padding:8px} "
        "th{background:#f4f4f4;text-align:left} a{text-decoration:none;color:#0366d6}</style>",
        "</head><body>",
        f"<h2>Index of {base_href or dir_path.as_posix()}</h2>",
        "<table><thead><tr><th>Name</th><th>Size</th><th>Modified</th></tr></thead><tbody>"
    ]
    # Add parent link if not at root of static/exports
    if dir_path != STATIC_EXPORTS:
        parent = dir_path.parent
        parent_href = (base_href.rsplit("/", 1)[0]) if "/" in base_href else ""
        html.append(f"<tr><td><a href='{parent_href or '.'}'>..</a></td><td>-</td><td>-</td></tr>")

    for name, href, size, mtime in entries:
        html.append(f"<tr><td><a href='{href}'>{name}</a></td><td>{size}</td><td>{mtime}</td></tr>")

    html.extend(["</tbody></table>",
                 "<p style='margin-top:20px;color:#666'>Generated by cwloop-webapp</p>",
                 "</body></html>"])

    (dir_path / "index.html").write_text("\n".join(html), encoding="utf-8")

def build_indexes_recursively(root: Path, base_href="/static/exports") -> None:
    """Create/refresh index.html in root and all subfolders."""
    for dirpath, dirnames, filenames in os.walk(root):
        d = Path(dirpath)
        relative = d.relative_to(root).as_posix()
        href = f"{base_href}/{relative}" if relative else base_href
        write_directory_index(d, base_href=href)

def recent_exports(limit: int = 12):
    """
    Return a list of recent export entries:
    [{'title':..., 'csv_url':..., 'html_url':..., 'folder_url':...}, ...]
    Scans static/exports/**/ for *.html and *.csv pairs.
    """
    results = []
    for html in STATIC_EXPORTS.rglob("*.html"):
        if html.name.lower() == "index.html":
            continue
        csv = html.with_suffix(".csv")
        date_folder = html.parents[1].name if html.parent.parent == STATIC_EXPORTS else html.parent.name
        title = html.stem.replace("-", " ").replace("_", " ").title()
        rel_dir = html.parent.relative_to(STATIC_EXPORTS).as_posix()
        results.append({
            "title": title,
            "date": date_folder,
            "html_url": f"/static/exports/{rel_dir}/{html.name}",
            "csv_url": f"/static/exports/{rel_dir}/{csv.name}" if csv.exists() else None,
            "folder_url": f"/static/exports/{rel_dir}/",
        })
    # sort by modtime desc
    results.sort(key=lambda x: Path(STATIC_EXPORTS / x["folder_url"].removeprefix("/static/exports/")).stat().st_mtime,
                 reverse=True)
    return results[:limit]

def slugify(s: str) -> str:
    s = s.strip().lower()
    s = re.sub(r"[^a-z0-9]+", "-", s)
    return s.strip("-") or "export"

# -----------------------------------------------------------------------------
# Routes
# -----------------------------------------------------------------------------
@app.route("/", methods=["GET"])
def index():
    """
    Home page with form and recent exports.
    Ensures (re)built directory indexes exist at static/exports for browsing.
    """
    # Build/refresh top-level index if it doesn't exist
    try:
        build_indexes_recursively(STATIC_EXPORTS, base_href="/static/exports")
    except Exception:
        # don't block homepage if this fails
        pass

    exports = recent_exports()
    # Template expects these keys. If you changed your template, adjust here:
    return render_template(
        "index.html",
        exports_list=exports,
        pushed=False,                    # kept for template compatibility
        site_base=STATIC_SITE_BASE or "",  # helps show static links
    )

@app.route("/rebuild-indexes", methods=["POST", "GET"])
def rebuild_indexes():
    """Rebuild index.html in static/exports and all subfolders."""
    build_indexes_recursively(STATIC_EXPORTS, base_href="/static/exports")
    if request.method == "GET":
        # For convenience in a browser
        return redirect(url_for("index"))
    return jsonify({"status": "ok", "message": "indexes rebuilt"})

@app.route("/process", methods=["POST"])
def process():
    """
    Pipeline:
    - Read original CSV (global timeline source) & additional CSVs
    - Use original's ' Time Stamp' (or best-guess) as the global X
    - Remove device prefixes from column names
    - Forward-fill sparse data onto global timeline
    - Save merged CSV + standalone Plotly HTML to static/exports/YYYY-MM-DD/<slug>/
    """
    if "original" not in request.files or request.files["original"].filename == "":
        abort(400, "Original CSV is required")

    original_file = request.files["original"]
    addl_files = request.files.getlist("additional") or []

    # UI params
    title = (request.form.get("title") or "CW Loop").strip()
    y1_min = request.form.get("y1_min", "0")
    y1_max = request.form.get("y1_max", "100")
    tolerance_s = int(request.form.get("tolerance", "5"))
    setpoint_col_hint = (request.form.get("setpoint_col") or "").strip()
    cutoff_dt = (request.form.get("cutoff_dt") or "").strip()

    # -----------------------------
    # Read & normalize original CSV
    # -----------------------------
    df0 = read_csv_storage(original_file)
    ts0 = find_timestamp_column(df0)
    if not ts0:
        abort(400, "Could not detect a timestamp column in the original CSV")

    df0 = normalize_datetime_index(df0, ts0)

    # apply optional cutoff
    if cutoff_dt:
        try:
            cutoff = pd.to_datetime(cutoff_dt)
            df0 = df0[df0.index >= cutoff]
        except Exception:
            pass

    # keep only numeric series, strip prefixes
    numeric_cols0 = [c for c in df0.columns if pd.api.types.is_numeric_dtype(df0[c])]
    df0 = df0[numeric_cols0]
    df0 = df0.rename(columns={c: strip_device_prefix(c) for c in df0.columns})

    # global index (original)
    idx = df0.index

    # ---------------------------------
    # Read & align additional CSV files
    # ---------------------------------
    aligned = [df0]
    for f in addl_files:
        if not f or not f.filename:
            continue
        try:
            d = read_csv_storage(f)
            tsc = find_timestamp_column(d) or ts0   # fall back to original's ts name if needed
            d = normalize_datetime_index(d, tsc)
            # numeric columns
            ncols = [c for c in d.columns if pd.api.types.is_numeric_dtype(d[c])]
            d = d[ncols]
            d = d.rename(columns={c: strip_device_prefix(c) for c in d.columns})
            # align to global timeline with forward-fill (limit by tolerance if wanted)
            d = d.reindex(idx).ffill()
            aligned.append(d)
        except Exception:
            continue

    # merge
    merged = pd.concat(aligned, axis=1)
    # collapse duplicate columns caused by overlaps by taking first non-null
    merged = merged.groupby(level=0, axis=1).first()

    # ---------------------------------
    # Build Plotly figure
    # ---------------------------------
    setpoint_lower = setpoint_col_hint.lower() if setpoint_col_hint else ""
    has_setpoint = None
    for c in merged.columns:
        if setpoint_lower and setpoint_lower == c.lower():
            has_setpoint = c
            break

    fig = make_subplots(specs=[[{"secondary_y": True}]])
    for col in merged.columns:
        if has_setpoint and col.lower() == has_setpoint.lower():
            fig.add_trace(
                go.Scatter(x=merged.index, y=merged[col], name=col, mode="lines"),
                secondary_y=True
            )
        else:
            fig.add_trace(
                go.Scatter(x=merged.index, y=merged[col], name=col, mode="lines"),
                secondary_y=False
            )

    fig.update_layout(
        title=title,
        hovermode="x unified",
        legend=dict(orientation="h", x=0, y=1.1),
        margin=dict(l=40, r=20, t=50, b=40),
    )
    fig.update_xaxes(title_text="Time Stamp")
    fig.update_yaxes(title_text="Percent", range=[float(y1_min), float(y1_max)], secondary_y=False)
    fig.update_yaxes(title_text="Setpoint", secondary_y=True)

    # ---------------------------------
    # Save outputs in dated folder
    # ---------------------------------
    today = datetime.now().strftime("%Y-%m-%d")
    sub = slugify(title)
    out_dir = STATIC_EXPORTS / today / sub if STATIC_DATED_SUBFOLDERS else STATIC_EXPORTS / sub
    out_dir.mkdir(parents=True, exist_ok=True)

    csv_path = out_dir / f"{sub}.csv"
    html_path = out_dir / f"{sub}.html"

    # Save merged CSV
    merged.reset_index().rename(columns={"index": "Time Stamp"}).to_csv(csv_path, index=False)

    # Save standalone Plotly HTML
    fig.write_html(str(html_path), include_plotlyjs="cdn", full_html=True)

    # Rebuild folder indexes so the static site is browsable immediately
    try:
        build_indexes_recursively(STATIC_EXPORTS, base_href="/static/exports")
    except Exception:
        pass

    # Provide direct links for the UI
    rel = out_dir.relative_to(STATIC_EXPORTS).as_posix()
    csv_url = f"/static/exports/{rel}/{csv_path.name}"
    html_url = f"/static/exports/{rel}/{html_path.name}"
    folder_url = f"/static/exports/{rel}/"

    # Return to index with a small success flash (template reads exports_list again)
    exports = recent_exports()
    return render_template(
        "index.html",
        exports_list=exports,
        pushed=False,
        site_base=STATIC_SITE_BASE or "",
        just_built={"title": title, "csv_url": csv_url, "html_url": html_url, "folder_url": folder_url},
    )

# -----------------------------------------------------------------------------
# Health
# -----------------------------------------------------------------------------
@app.route("/health")
def health():
    return "ok", 200

# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    # For local dev only; Render will use gunicorn
    app.run(host="0.0.0.0", port=5000, debug=True)
